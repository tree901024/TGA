{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 18:01:21.497363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-01 18:01:21.497402: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====data load===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (872, 2) (1821, 2) min_co : 5\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/sst-2/train.csv\")\n",
    "val = pd.read_csv(\"./data/sst-2/val.csv\")\n",
    "test = pd.read_csv(\"./data/sst-2/test.csv\")\n",
    "\n",
    "df = pd.DataFrame(train)\n",
    "train = df.sample(n=2000, random_state=7)\n",
    "\n",
    "min_co = 5\n",
    "print(train.shape, val.shape, test.shape, \"min_co :\", min_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====AUG 시작 ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_only_chars(line):\n",
    "\n",
    "    clean_line = \"\"\n",
    "\n",
    "    line = line.replace(\"’\", \"\")\n",
    "    line = line.replace(\"'\", \"\")\n",
    "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
    "    line = line.replace(\"\\t\", \" \")\n",
    "    line = line.replace(\"\\n\", \" \")\n",
    "    line = line.lower()\n",
    "\n",
    "    for char in line:\n",
    "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
    "            clean_line += char\n",
    "        else:\n",
    "            clean_line += ' '\n",
    "\n",
    "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
    "    if clean_line[0] == ' ':\n",
    "        clean_line = clean_line[1:]\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====Graph 만들기==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def scan_vocabulary(train_input, min_count=2):\n",
    "    counter = Counter(w for sent in train_input for w in sent)\n",
    "    counter = {w:c for w,c in counter.items() if c >= min_count}\n",
    "    idx_to_vocab = [w for w, _ in sorted(counter.items(), key=lambda x:-x[1])]\n",
    "    vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
    "    return idx_to_vocab, vocab_to_idx\n",
    "\n",
    "def dict_to_mat(d, n_rows, n_cols):\n",
    "    rows, cols, data = [], [], []\n",
    "    for (i, j), v in d.items():\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "        data.append(v)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))\n",
    "\n",
    "def cooccurrence(tokens, vocab_to_idx, window=2, min_cooccurrence=min_co):\n",
    "    counter = defaultdict(int)\n",
    "    for s, tokens_i in enumerate(tokens):\n",
    "        vocabs = [vocab_to_idx[w] for w in tokens_i if w in vocab_to_idx]\n",
    "        n = len(vocabs)\n",
    "        for i, v in enumerate(vocabs):\n",
    "            if window <= 0:\n",
    "                b, e = 0, n\n",
    "            else:\n",
    "                b = max(0, i - window)\n",
    "                e = min(i + window, n)\n",
    "            for j in range(b, e):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                counter[(v, vocabs[j])] += 1\n",
    "                counter[(vocabs[j], v)] += 1\n",
    "    counter = {k:v for k,v in counter.items() if v >= min_cooccurrence}\n",
    "    n_vocabs = len(vocab_to_idx)\n",
    "    return dict_to_mat(counter, n_vocabs, n_vocabs), counter\n",
    "\n",
    "def word_graph(train_input, min_count=2, window=2, min_cooccurrence=min_co):\n",
    "    idx_to_vocab, vocab_to_idx = scan_vocabulary(train_input, min_count)\n",
    "    tokens = [sent for sent in train_input]\n",
    "    g, counter = cooccurrence(tokens, vocab_to_idx, window, min_cooccurrence)\n",
    "    return g, idx_to_vocab, vocab_to_idx, counter\n",
    "def get_graph_input(data):\n",
    "    vocab = []\n",
    "    train_input = []\n",
    "    train_label = []\n",
    "    for sentence, label in zip(data[\"sentence\"], data[\"label\"]):\n",
    "        token_sen = get_only_chars(sentence)\n",
    "        words = token_sen.split(' ')\n",
    "        train_input.append(words)\n",
    "        train_label.append(label)\n",
    "        for word in words:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "            else:\n",
    "                pass\n",
    "    return vocab, train_input, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7098 2000 2000\n"
     ]
    }
   ],
   "source": [
    "vocab, train_input, train_label = get_graph_input(train)\n",
    "print(len(vocab), len(train_input), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data_input = []\n",
    "    data_label = []\n",
    "    for no, sentence in enumerate(data[\"sentence\"]):\n",
    "        token_sen = get_only_chars(sentence)\n",
    "        words = token_sen.split(' ')\n",
    "        data_input.append(words)\n",
    "        data_label.append(data[\"label\"][no])\n",
    "    return data_input, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input, val_label = preprocessing(val)\n",
    "test_input, test_label = preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(train_input):\n",
    "    g, idx_to_vocab, vocab_to_idx, counter = word_graph(train_input)\n",
    "    mat = g.toarray()\n",
    "    print(\"vocab :\", len(vocab), \"   \", \"idx_to_vocab :\", len(idx_to_vocab))\n",
    "    print(\"vocab_to_idx = vocab : idx\")\n",
    "    print(\"counter = (node1, node2) : number\")\n",
    "    \n",
    "    #make a edge\n",
    "    edge_list = []\n",
    "\n",
    "    for i, j in enumerate(mat):\n",
    "        for l, occurance in enumerate(j):\n",
    "            if occurance != 0:\n",
    "                edge_list.append([vocab_to_idx[idx_to_vocab[i]], vocab_to_idx[idx_to_vocab[l]]])\n",
    "            else:\n",
    "                pass\n",
    "    print(\"edge_list_len : \", len(edge_list))\n",
    "    edge_index = torch.Tensor(edge_list).long()\n",
    "    \n",
    "    #make a node\n",
    "    node_list = []\n",
    "    for i in vocab_to_idx.values():\n",
    "        node_list.append([i])\n",
    "    print(\"node_list_len : \", len(node_list))\n",
    "    node_index = torch.Tensor(node_list).float()\n",
    "    \n",
    "    print(\"edge, node size : \", edge_index.size(), node_index.size())\n",
    "    \n",
    "\n",
    "    graph_data = Data(x=node_index, edge_index = edge_index.t().contiguous())\n",
    "    print(\"graph_data : \", graph_data)\n",
    "    \n",
    "    print(\"node : \", graph_data.num_nodes, \"edge : \", graph_data.num_edges,\n",
    "          \"isolated node have : \", graph_data.contains_isolated_nodes(), \n",
    "          \"self loop node have : \", graph_data.contains_self_loops(), \n",
    "          \"key : \", graph_data.keys)\n",
    "    return graph_data, vocab_to_idx, idx_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab : 7098     idx_to_vocab : 2863\n",
      "vocab_to_idx = vocab : idx\n",
      "counter = (node1, node2) : number\n",
      "edge_list_len :  5156\n",
      "node_list_len :  2863\n",
      "edge, node size :  torch.Size([5156, 2]) torch.Size([2863, 1])\n",
      "graph_data :  Data(x=[2863, 1], edge_index=[2, 5156])\n",
      "node :  2863 edge :  5156 isolated node have :  True self loop node have :  True key :  ['x', 'edge_index']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aitree/.conda/envs/tree90/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n",
      "/home/aitree/.conda/envs/tree90/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "graph_data, vocab_to_idx, idx_to_vocab = make_graph(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873\n"
     ]
    }
   ],
   "source": [
    "edge_dic = {}\n",
    "for i in graph_data.edge_index.t().numpy():\n",
    "    if i[0] not in edge_dic.keys():\n",
    "        edge_dic[i[0]] = [i[1]]\n",
    "    else:\n",
    "        edge_dic[i[0]].append(i[1])\n",
    "print(len(edge_dic.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===AUG 기법 적용 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tga03(train_input, train_label, graph_data, vocab_to_idx):\n",
    "    aug_train_input = []\n",
    "    aug_train_label = []\n",
    "    for no, sentence in enumerate(train_input):        \n",
    "        init_nodes_idx=[]\n",
    "        nodes_idx = []\n",
    "        for word in sentence:\n",
    "            if word in vocab_to_idx.keys():\n",
    "                nodes_idx.append(vocab_to_idx[word])\n",
    "                init_nodes_idx.append(vocab_to_idx[word])\n",
    "        num_edge = 10000\n",
    "        init_node_idx = 2**100\n",
    "        sw_node_idx = 2**100\n",
    "        for node_idx in nodes_idx:\n",
    "            if node_idx not in edge_dic.keys():\n",
    "                nodes_idx.remove(node_idx)\n",
    "                continue\n",
    "            edge_list = edge_dic[node_idx]            \n",
    "            for edge_node in edge_list:\n",
    "                if edge_node not in init_nodes_idx:\n",
    "                    edge_list.remove(edge_node)            \n",
    "                    continue\n",
    "            if len(edge_list) ==0:\n",
    "                nodes_idx.remove(node_idx)\n",
    "                continue                    \n",
    "            if len(edge_list) < num_edge:\n",
    "                num_edge = len(edge_list)\n",
    "                init_node_idx = node_idx\n",
    "                sw_node_idx = random.choice(edge_list)\n",
    "        augdel_sentence = []+sentence\n",
    "        augrep_sentence = []+sentence\n",
    "        augsw_sentence = []+sentence\n",
    "        augins_sentence = []+sentence\n",
    "        if init_node_idx == 2**100:\n",
    "            continue\n",
    "        augdel_sentence.remove(idx_to_vocab[init_node_idx])\n",
    "        aug_train_input.append(augdel_sentence)\n",
    "        aug_train_label.append(train_label[no])          \n",
    "        \n",
    "        if sw_node_idx != 2**100:\n",
    "            init_word_index = 0\n",
    "            sw_word_index = 0\n",
    "            for index, word in enumerate(sentence):\n",
    "                if word not in vocab_to_idx.keys():\n",
    "                    continue \n",
    "                if vocab_to_idx[word] == init_node_idx:\n",
    "                    init_word_index = index\n",
    "                if vocab_to_idx[word] == sw_node_idx:\n",
    "                    sw_word_index = index\n",
    "            augsw_sentence[sw_word_index] = idx_to_vocab[init_node_idx]\n",
    "            augsw_sentence[init_word_index] = idx_to_vocab[sw_node_idx]\n",
    "            aug_train_input.append(augsw_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "        \n",
    "        candidate = edge_dic[init_node_idx]\n",
    "        if len(candidate) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            augrep_sentence[init_word_index] = idx_to_vocab[random.choice(candidate)]\n",
    "            aug_train_input.append(augrep_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "            augrep_sentence[init_word_index] = idx_to_vocab[random.choice(candidate)]\n",
    "            aug_train_input.append(augrep_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "            augins_sentence.insert(init_word_index, idx_to_vocab[random.choice(candidate)])\n",
    "            aug_train_input.append(augins_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "            augins_sentence.insert(init_word_index, idx_to_vocab[random.choice(candidate)])\n",
    "            aug_train_input.append(augins_sentence)    \n",
    "            aug_train_label.append(train_label[no])    \n",
    "                    \n",
    "        aug_train_input.append(sentence)\n",
    "        aug_train_label.append(train_label[no])    \n",
    "    return aug_train_input, aug_train_label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tga01(train_input, train_label, graph_data, vocab_to_idx):\n",
    "    aug_train_input = []\n",
    "    aug_train_label = []\n",
    "    for no, sentence in enumerate(train_input):        \n",
    "        init_nodes_idx=[]\n",
    "        nodes_idx = []\n",
    "        for word in sentence:\n",
    "            if word in vocab_to_idx.keys():\n",
    "                nodes_idx.append(vocab_to_idx[word])\n",
    "                init_nodes_idx.append(vocab_to_idx[word])\n",
    "        num_edge = 0\n",
    "        init_node_idx = 2**100\n",
    "        sw_node_idx = 2**100\n",
    "        for node_idx in nodes_idx:\n",
    "            if node_idx not in edge_dic.keys():\n",
    "                nodes_idx.remove(node_idx)\n",
    "                continue\n",
    "            edge_list = edge_dic[node_idx]            \n",
    "            if len(edge_list) ==0:\n",
    "                nodes_idx.remove(node_idx)\n",
    "                continue\n",
    "            for edge_node in edge_list:\n",
    "                if edge_node not in init_nodes_idx:\n",
    "                    edge_list.remove(edge_node)            \n",
    "                    continue\n",
    "            if len(edge_list) > num_edge:\n",
    "                num_edge = len(edge_list)\n",
    "                init_node_idx = node_idx\n",
    "                sw_node_idx = random.choice(edge_list)\n",
    "        augdel_sentence = []+sentence\n",
    "        augrep_sentence = []+sentence\n",
    "        augsw_sentence = []+sentence\n",
    "        augins_sentence = []+sentence\n",
    "        if init_node_idx == 2**100:\n",
    "            continue\n",
    "        augdel_sentence.remove(idx_to_vocab[init_node_idx])\n",
    "        aug_train_input.append(augdel_sentence)\n",
    "        aug_train_label.append(train_label[no])          \n",
    "        \n",
    "        if sw_node_idx != 2**100:\n",
    "            init_word_index = 0\n",
    "            sw_word_index = 0\n",
    "            for index, word in enumerate(sentence):\n",
    "                if word not in vocab_to_idx.keys():\n",
    "                    continue \n",
    "                if vocab_to_idx[word] == init_node_idx:\n",
    "                    init_word_index = index\n",
    "                if vocab_to_idx[word] == sw_node_idx:\n",
    "                    sw_word_index = index\n",
    "            augsw_sentence[sw_word_index] = idx_to_vocab[init_node_idx]\n",
    "            augsw_sentence[init_word_index] = idx_to_vocab[sw_node_idx]\n",
    "            aug_train_input.append(augsw_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "        \n",
    "        candidate = edge_dic[init_node_idx]\n",
    "        if len(candidate) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            augrep_sentence[init_word_index] = idx_to_vocab[random.choice(candidate)]\n",
    "            aug_train_input.append(augrep_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "            augrep_sentence[init_word_index] = idx_to_vocab[random.choice(candidate)]\n",
    "            aug_train_input.append(augrep_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "            augins_sentence.insert(init_word_index, idx_to_vocab[random.choice(candidate)])\n",
    "            aug_train_input.append(augins_sentence)\n",
    "            aug_train_label.append(train_label[no])    \n",
    "            augins_sentence.insert(init_word_index, idx_to_vocab[random.choice(candidate)])\n",
    "            aug_train_input.append(augins_sentence)    \n",
    "            aug_train_label.append(train_label[no])    \n",
    "                    \n",
    "        aug_train_input.append(sentence)\n",
    "        aug_train_label.append(train_label[no])    \n",
    "    return aug_train_input, aug_train_label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_input, aug_train_label = tga03(train_input, train_label, graph_data, vocab_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 13391 13391\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_input), len(aug_train_input), len(aug_train_label)), print(min_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(input_data):\n",
    "    temp_inputs = []\n",
    "    for sentence in input_data:\n",
    "        temp_inputs.append(\" \".join(sentence))\n",
    "    return temp_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_inputs = convert_input(aug_train_input)\n",
    "val_inputs = convert_input(val_input)\n",
    "test_inputs = convert_input(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====data preprocessing===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class text(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(inputs, label):\n",
    "    sentences = inputs\n",
    "    labels = label\n",
    "    print(\"sentences : \", len(sentences), \"labels : \", len(labels))\n",
    "    max_len = 128\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding=True)\n",
    "    dataset = text(tokenized, labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences :  13391 labels :  13391\n",
      "sentences :  872 labels :  872\n",
      "sentences :  1821 labels :  1821\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(aug_train_inputs, aug_train_label)\n",
    "val_dataset = make_dataset(val_inputs, val_label)\n",
    "test_dataset = make_dataset(test_inputs, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== BERT ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.3235592667368196\n",
      "---training epoch took :  0:01:16\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8946428571428572\n",
      " Val took :  0:01:17\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.034031161067209076\n",
      "---training epoch took :  0:01:19\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8964285714285715\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.016863448481031117\n",
      "---training epoch took :  0:01:19\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8868303571428572\n",
      " Val took :  0:01:21\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.004277948725835553\n",
      "---training epoch took :  0:01:19\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8863839285714287\n",
      " Val took :  0:01:21\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.005066083256609826\n",
      "---training epoch took :  0:01:19\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8727678571428571\n",
      " Val took :  0:01:21\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.004435032616241924\n",
      "---training epoch took :  0:01:19\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8850446428571429\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.006278764179054027\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8901785714285715\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.006352948190760798\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8857142857142858\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.0017974339065230673\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8892857142857142\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.0003396789627177419\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8839285714285714\n",
      " Val took :  0:01:20\n",
      "Training complete\n",
      " test_accuracy :  0.8828589476813317\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.279878058390958\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8763392857142858\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.03352419794315384\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8901785714285715\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.01218162903872629\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8879464285714286\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.009663358224844116\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8772321428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.008464655793172174\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8901785714285715\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.008169512904714793\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8897321428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.0027991561801172793\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8941964285714287\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.0031765086705230973\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9004464285714285\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.0017226654352963946\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8950892857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.0038080577157199426\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9026785714285713\n",
      " Val took :  0:01:19\n",
      "Training complete\n",
      " test_accuracy :  0.8980566290130796\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.28456493448022574\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8810267857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.034649766878491\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8877232142857142\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.013441493298714271\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8950892857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.00532644794272658\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8899553571428571\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.002891246109945877\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8839285714285714\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.003195042652355152\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8897321428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.002406558456450945\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8875000000000001\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.00038266642846532966\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8866071428571428\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.0034203795103253686\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8845982142857143\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.002295725733503267\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8808035714285715\n",
      " Val took :  0:01:20\n",
      "Training complete\n",
      " test_accuracy :  0.8884512485136742\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.2802179616388111\n",
      "---training epoch took :  0:01:17\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8783482142857143\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.03835117303367172\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8966517857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.022833154503522173\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8944196428571428\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.007626581082253584\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8863839285714287\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.00701026773922855\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8912946428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.006947609108395963\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8948660714285713\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.003510275148160179\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8912946428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.002819950958170618\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8997767857142858\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.003117197117812577\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8729910714285715\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.001425104592635762\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8852678571428572\n",
      " Val took :  0:01:20\n",
      "Training complete\n",
      " test_accuracy :  0.8872807669441142\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.2718585896616181\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8883928571428571\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.035701010249821204\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.890625\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.011729505650388697\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8859374999999999\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.009952433956676119\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8895089285714286\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.006969144642408494\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8799107142857142\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.002290141129023617\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8921875\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.0036392658319701217\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8850446428571429\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.0029496763142690596\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8910714285714285\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.0037197584753379314\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9017857142857143\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.00279576592701709\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8953125000000001\n",
      " Val took :  0:01:19\n",
      "Training complete\n",
      " test_accuracy :  0.89482387039239\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.28446609752164\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8796875000000001\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.04062493936868296\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8912946428571429\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.019913315760814364\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8848214285714285\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.014232135236462844\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8883928571428571\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.008359507983550429\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8899553571428571\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.008822529983063716\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8883928571428571\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.008109274264036988\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8908482142857144\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.002889933968046015\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8861607142857143\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.003002151640664254\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8683035714285714\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.0036260432319804316\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8707589285714287\n",
      " Val took :  0:01:19\n",
      "Training complete\n",
      " test_accuracy :  0.8705596016646848\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.25186142789288646\n",
      "---training epoch took :  0:01:17\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8946428571428572\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.030345605718459758\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8919642857142858\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.013584412442564609\n",
      "---training epoch took :  0:01:19\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8928571428571429\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.006836462310803611\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9035714285714286\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.003407987941699546\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8950892857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.0031625341272003772\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.0018155005950358741\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8881696428571428\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.00473002124573603\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.88125\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.002662517628050409\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8839285714285714\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.0018632291346702481\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8937499999999999\n",
      " Val took :  0:01:20\n",
      "Training complete\n",
      " test_accuracy :  0.8902905766944115\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.33461703459421793\n",
      "---training epoch took :  0:01:17\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8763392857142858\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.04571172697247849\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8863839285714287\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.01924738162418916\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8819196428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.012314435583539307\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8834821428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.006908645042373488\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.884375\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.007581328887802859\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8852678571428572\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.00422306666621894\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8986607142857144\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.0032794820549454365\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8982142857142856\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.0010462935837928116\n",
      "---training epoch took :  0:01:17\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8982142857142856\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.002279877148768199\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8745535714285715\n",
      " Val took :  0:01:19\n",
      "Training complete\n",
      " test_accuracy :  0.8697049643281808\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.27893046539365535\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8995535714285714\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.03181663874780671\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8935267857142858\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.009376075699748028\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8953125000000001\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.007366366571347628\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8912946428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.00572816553910906\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8926339285714285\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.0053195147233227975\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8966517857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.004911912488751113\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9006696428571429\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.0024637628167207973\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9029017857142857\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.0008571759954931968\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.9040178571428571\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.002314422290891387\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.896875\n",
      " Val took :  0:01:19\n",
      "Training complete\n",
      " test_accuracy :  0.900323275862069\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Epoch :  1 / 10 ===\n",
      "---Average training loss :  0.25892000557145195\n",
      "---training epoch took :  0:01:17\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8926339285714285\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  2 / 10 ===\n",
      "---Average training loss :  0.03115159507530431\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.890625\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  3 / 10 ===\n",
      "---Average training loss :  0.017839705774427523\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.884375\n",
      " Val took :  0:01:20\n",
      "\n",
      "===Epoch :  4 / 10 ===\n",
      "---Average training loss :  0.008243330575281843\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8915178571428571\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  5 / 10 ===\n",
      "---Average training loss :  0.0047283358743048405\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8917410714285714\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  6 / 10 ===\n",
      "---Average training loss :  0.0060530613346989936\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8868303571428572\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  7 / 10 ===\n",
      "---Average training loss :  0.0058280921604905635\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8752232142857144\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  8 / 10 ===\n",
      "---Average training loss :  0.0031874028089944094\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8854910714285714\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  9 / 10 ===\n",
      "---Average training loss :  0.003078895994916647\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8964285714285715\n",
      " Val took :  0:01:19\n",
      "\n",
      "===Epoch :  10 / 10 ===\n",
      "---Average training loss :  0.002095811002142173\n",
      "---training epoch took :  0:01:18\n",
      "===Running Validation===\n",
      " Val_accuracy :  0.8899553571428571\n",
      " Val took :  0:01:19\n",
      "Training complete\n",
      " test_accuracy :  0.888655618311534\n",
      " test took :  0:00:03\n",
      "Test complete\n"
     ]
    }
   ],
   "source": [
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "BERTmodel.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
    "optim = AdamW(BERTmodel.parameters(), lr=0.00001)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print(\"===Epoch : \", epoch+1, \"/\", epochs, \"===\")\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    BERTmodel.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss=outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(\"---Average training loss : \", avg_train_loss)\n",
    "    print(\"---training epoch took : \", format_time(time.time()-t0))\n",
    "    print(\"===Running Validation===\")    \n",
    "    \n",
    "    BERTmodel.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in eval_loader:        \n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            b_outputs = BERTmodel(b_input_ids, attention_mask=b_attention_mask)\n",
    "        \n",
    "        logits = b_outputs[0]\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps +=1\n",
    "    print(\" Val_accuracy : \", eval_accuracy/nb_eval_steps)\n",
    "    print(\" Val took : \", format_time(time.time()-t0))\n",
    "print(\"Training complete\")\n",
    "\n",
    "t0 = time.time()\n",
    "BERTmodel.eval()\n",
    "\n",
    "test_loss, test_accuracy = 0, 0\n",
    "test_steps, test_examples = 0, 0\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
    "for step, batch in enumerate(test_loader):        \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs[0]       \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "    test_steps +=1\n",
    "print(\" test_accuracy : \", test_accuracy/test_steps)\n",
    "print(\" test took : \", format_time(time.time()-t0))\n",
    "print(\"Test complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree90",
   "language": "python",
   "name": "tree90"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
